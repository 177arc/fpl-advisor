{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantasy Premier League (FPL) Advisor Neural Network Model Builder\n",
    "\n",
    "The purpose of this notebook is to train a neural network that can predict the expected points for specific player and fixture combination. Currently, the training data is based on [fpl-data](https://github.com/177arc/fpl-data) which contains a rolling window of fixtures from this and the past season.\n",
    "\n",
    "# Installation\n",
    "To get started, run the following command to install all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T20:41:37.990718Z",
     "start_time": "2020-11-15T20:41:37.980718Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -q -r requirements.txt\n",
    "#!pip install -q -r requirements_nn.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import requirements\n",
    "Here we import all external and local modulues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:21.307192Z",
     "start_time": "2020-11-16T08:41:16.612998Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, os, sys\n",
    "from fplpandas import FPLPandas\n",
    "from datadict.jupyter import DataDict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load local modules\n",
    "sys.path.append(os.getcwd())\n",
    "from data import get_df\n",
    "from nn import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set variables\n",
    "This section sets all important global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:21.323196Z",
     "start_time": "2020-11-16T08:41:21.309195Z"
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://s3.eu-west-2.amazonaws.com/fpl-test.177arc.net/v1/latest/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-processed data\n",
    "This section loads data sets generated by the [fpl-data](https://github.com/177arc/fpl-data) lambda function and made available via the S3 bucket specified in the `data_url` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:22.182196Z",
     "start_time": "2020-11-16T08:41:21.326195Z"
    }
   },
   "outputs": [],
   "source": [
    "players_fixture_team_eps_ext = get_df(url=f'{data_url}players_fixture_team_eps_ext.csv', index=['Player Code', 'Season', 'Game Week'])\n",
    "players_fixture_team_eps_ext.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T15:20:57.167372Z",
     "start_time": "2020-02-16T15:20:57.163383Z"
    }
   },
   "source": [
    "## Create training and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:23.332194Z",
     "start_time": "2020-11-16T08:41:23.173197Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = (players_fixture_team_eps_ext\n",
    "    .reset_index()\n",
    "#    [['Fixture Total Points', 'Field Position', 'Total Points To Fixture', 'Is Home?', 'Fixtures Played To Fixture', 'Opp Team FDR']]\n",
    "    [lambda df: df['Fixture Minutes Played'] > 0]    \n",
    "    [['Fixture Total Points', 'Field Position', 'Total Points To Fixture', 'Fixtures Played To Fixture', 'Opp Team FDR']]\n",
    "#    .assign(**{'Total Points': lambda df: df['Fixture Total Points']}\n",
    "    .dropna(how='any', axis=0)\n",
    "    .pipe(nn_split, frac=0.8))\n",
    "train_ds = train_df.pipe(nn_prep_ds, 'Fixture Total Points')\n",
    "test_ds = test_df.pipe(nn_prep_ds, 'Fixture Total Points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:24.635790Z",
     "start_time": "2020-11-16T08:41:24.619791Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns_cats = {'field_position': ['GK', 'DEF', 'MID', 'FWD']}\n",
    "\n",
    "feature_columns = []\n",
    "for col, spec in train_ds.element_spec[0].items():\n",
    "    if spec.dtype in [tf.bool, tf.float64]:\n",
    "        feature_columns.append(feature_column.numeric_column(col))\n",
    "        \n",
    "    if col in feature_columns_cats.keys():\n",
    "        field_pos = feature_column.categorical_column_with_vocabulary_list(col, feature_columns_cats[col])\n",
    "        field_pos_one_hot = feature_column.indicator_column(field_pos)\n",
    "        feature_columns.append(field_pos_one_hot)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "Here we create a neural network with four layers. Although ultimately the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:25.974809Z",
     "start_time": "2020-11-16T08:41:25.921811Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.DenseFeatures(feature_columns, dtype='float64'),\n",
    "  layers.Dense(4, activation='relu', dtype='float64'),\n",
    "  layers.Dense(3, activation='relu', dtype='float64'),\n",
    "  layers.Dense(1, dtype='float64')\n",
    "])\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "                metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:45.553835Z",
     "start_time": "2020-11-16T08:41:27.129811Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "train_history = model.fit(train_ds,\n",
    "          validation_data=test_ds,\n",
    "          epochs=60,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:47.903848Z",
     "start_time": "2020-11-16T08:41:47.755852Z"
    }
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "plotter.plot({'Early Stopping': train_history}, metric = 'mse')\n",
    "plt.ylabel('MSE [Fixture]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:49.618874Z",
     "start_time": "2020-11-16T08:41:49.346876Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_ds).flatten()\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_df['Fixture Total Points'], test_predictions)\n",
    "plt.xlabel('True Values [Fixture Total Points]')\n",
    "plt.ylabel('Predictions [Fixture Total Points]')\n",
    "lims = [-3, 20]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:41:50.691880Z",
     "start_time": "2020-11-16T08:41:50.666882Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df['Predicted'] = test_predictions\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T20:42:12.813541Z",
     "start_time": "2020-11-15T20:42:11.788543Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models/expected_points')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
